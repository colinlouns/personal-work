{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Using Reddit's API for Predicting Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T19:28:02.619411Z",
     "start_time": "2017-10-23T19:28:02.600856Z"
    }
   },
   "source": [
    "In this project, we will practice two major skills. Collecting data via an API request and then building a binary predictor.\n",
    "\n",
    "As we discussed in week 2, and earlier today, there are two components to starting a data science problem: the problem statement, and acquiring the data.\n",
    "\n",
    "For this article, your problem statement will be: _What characteristics of a post on Reddit contribute most to what subreddit it belongs to?_\n",
    "\n",
    "Your method for acquiring the data will be scraping threads from at least two subreddits. \n",
    "\n",
    "Once you've got the data, you will build a classification model that, using Natural Language Processing and any other relevant features, predicts which subreddit a given post belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping Thread Info from Reddit.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. \n",
    "\n",
    "*NOTE*: Reddit will throw a [429 error](https://httpstatuses.com/429) when using the following code:\n",
    "```python\n",
    "res = requests.get(URL)\n",
    "```\n",
    "\n",
    "This is because Reddit has throttled python's default user agent. You'll need to set a custom `User-agent` to get your request to work.\n",
    "```python\n",
    "res = requests.get(URL, headers={'User-agent': 'YOUR NAME Bot 0.1'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup   \n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(subreddit, after = None):\n",
    "    url = f'https://www.reddit.com/r/{subreddit}/.json'\n",
    "    headers = {'User-agent': 'webscraping bot'}\n",
    "    params = {'after' : after}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    return r.json()['data']['children']\n",
    "\n",
    "def parse_post(post):\n",
    "    keep = ['subreddit','selftext','title','score','name','author','num_comments','permalink','stickied','url']\n",
    "    data = post['data']\n",
    "    return {k: v for k, v in data.items() if k in keep}\n",
    "\n",
    "def parsed_page(page):\n",
    "    parsed_posts = []\n",
    "    after = ''\n",
    "    for post in page:\n",
    "        p = parse_post(post)\n",
    "        after = p['name']\n",
    "        parsed_posts.append(p)\n",
    "    return parsed_posts, after\n",
    "\n",
    "def fetch_subreddit(subreddit, pages = 4):\n",
    "    all_posts = []\n",
    "    after = ''\n",
    "    for i in range(pages):\n",
    "        print(f'Fetching Page {i}')\n",
    "        page = fetch_page(subreddit, after)\n",
    "        parsed_posts, after = parsed_page(page)\n",
    "        all_posts.extend(parsed_posts)\n",
    "        sleep(5)\n",
    "    return all_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Page 0\n",
      "Fetching Page 1\n",
      "Fetching Page 2\n",
      "Fetching Page 3\n",
      "Fetching Page 4\n",
      "Fetching Page 5\n",
      "Fetching Page 6\n",
      "Fetching Page 7\n",
      "Fetching Page 8\n",
      "Fetching Page 9\n",
      "Fetching Page 10\n",
      "Fetching Page 11\n",
      "Fetching Page 12\n",
      "Fetching Page 13\n",
      "Fetching Page 14\n",
      "Fetching Page 15\n",
      "Fetching Page 16\n",
      "Fetching Page 17\n",
      "Fetching Page 18\n",
      "Fetching Page 19\n",
      "Fetching Page 20\n",
      "Fetching Page 21\n",
      "Fetching Page 22\n",
      "Fetching Page 23\n",
      "Fetching Page 24\n",
      "Fetching Page 25\n",
      "Fetching Page 26\n",
      "Fetching Page 27\n",
      "Fetching Page 28\n",
      "Fetching Page 29\n",
      "Fetching Page 30\n",
      "Fetching Page 31\n",
      "Fetching Page 32\n",
      "Fetching Page 33\n",
      "Fetching Page 34\n",
      "Fetching Page 35\n",
      "Fetching Page 36\n",
      "Fetching Page 37\n",
      "Fetching Page 38\n",
      "Fetching Page 39\n",
      "Fetching Page 0\n",
      "Fetching Page 1\n",
      "Fetching Page 2\n",
      "Fetching Page 3\n",
      "Fetching Page 4\n",
      "Fetching Page 5\n",
      "Fetching Page 6\n",
      "Fetching Page 7\n",
      "Fetching Page 8\n",
      "Fetching Page 9\n",
      "Fetching Page 10\n",
      "Fetching Page 11\n",
      "Fetching Page 12\n",
      "Fetching Page 13\n",
      "Fetching Page 14\n",
      "Fetching Page 15\n",
      "Fetching Page 16\n",
      "Fetching Page 17\n",
      "Fetching Page 18\n",
      "Fetching Page 19\n",
      "Fetching Page 20\n",
      "Fetching Page 21\n",
      "Fetching Page 22\n",
      "Fetching Page 23\n",
      "Fetching Page 24\n",
      "Fetching Page 25\n",
      "Fetching Page 26\n",
      "Fetching Page 27\n",
      "Fetching Page 28\n",
      "Fetching Page 29\n",
      "Fetching Page 30\n",
      "Fetching Page 31\n",
      "Fetching Page 32\n",
      "Fetching Page 33\n",
      "Fetching Page 34\n",
      "Fetching Page 35\n",
      "Fetching Page 36\n",
      "Fetching Page 37\n",
      "Fetching Page 38\n",
      "Fetching Page 39\n"
     ]
    }
   ],
   "source": [
    "subreddit1 = fetch_subreddit('dota2', pages = 40)\n",
    "subreddit2 = fetch_subreddit('baseball', pages = 40)\n",
    "sub1 = pd.DataFrame(subreddit1)\n",
    "sub2 = pd.DataFrame(subreddit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1['r_dota2'] = 1\n",
    "sub1['r_baseball'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>r_dota2</th>\n",
       "      <th>r_baseball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VRCkid</td>\n",
       "      <td>t3_ag5vek</td>\n",
       "      <td>171</td>\n",
       "      <td>/r/DotA2/comments/ag5vek/rdota2_2019_survey_up...</td>\n",
       "      <td>274</td>\n",
       "      <td>Hey /r/DotA2!\\n\\nSince we're at the start of a...</td>\n",
       "      <td>True</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>/r/Dota2 2019 Survey &amp;amp; Updates</td>\n",
       "      <td>https://www.reddit.com/r/DotA2/comments/ag5vek...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VRCbot</td>\n",
       "      <td>t3_aiaulg</td>\n",
       "      <td>64</td>\n",
       "      <td>/r/DotA2/comments/aiaulg/the_349th_weekly_stup...</td>\n",
       "      <td>10</td>\n",
       "      <td>\\nReady the questions! Feel free to ask anythi...</td>\n",
       "      <td>True</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>The 349th Weekly Stupid Questions Thread</td>\n",
       "      <td>https://www.reddit.com/r/DotA2/comments/aiaulg...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwer4790</td>\n",
       "      <td>t3_ai9hp2</td>\n",
       "      <td>321</td>\n",
       "      <td>/r/DotA2/comments/ai9hp2/shadow_in_hospital_to...</td>\n",
       "      <td>1241</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>Shadow in hospital too due to bad food</td>\n",
       "      <td>https://i.redd.it/yuvgsf9unrb21.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PSGLGD-Baka</td>\n",
       "      <td>t3_ai8f9v</td>\n",
       "      <td>169</td>\n",
       "      <td>/r/DotA2/comments/ai8f9v/lmao_l_know_why_they_...</td>\n",
       "      <td>1257</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>Lmao, l know why they lose</td>\n",
       "      <td>https://i.redd.it/fneh4ppatqb21.gif</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lelANDtoplel</td>\n",
       "      <td>t3_ai9qin</td>\n",
       "      <td>99</td>\n",
       "      <td>/r/DotA2/comments/ai9qin/congratulations_to_th...</td>\n",
       "      <td>474</td>\n",
       "      <td>With their win over Evil Geniuses, Virtus Pro ...</td>\n",
       "      <td>False</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>Congratulations to the first team to qualify f...</td>\n",
       "      <td>https://www.reddit.com/r/DotA2/comments/ai9qin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author       name  num_comments  \\\n",
       "0        VRCkid  t3_ag5vek           171   \n",
       "1        VRCbot  t3_aiaulg            64   \n",
       "2      qwer4790  t3_ai9hp2           321   \n",
       "3   PSGLGD-Baka  t3_ai8f9v           169   \n",
       "4  lelANDtoplel  t3_ai9qin            99   \n",
       "\n",
       "                                           permalink  score  \\\n",
       "0  /r/DotA2/comments/ag5vek/rdota2_2019_survey_up...    274   \n",
       "1  /r/DotA2/comments/aiaulg/the_349th_weekly_stup...     10   \n",
       "2  /r/DotA2/comments/ai9hp2/shadow_in_hospital_to...   1241   \n",
       "3  /r/DotA2/comments/ai8f9v/lmao_l_know_why_they_...   1257   \n",
       "4  /r/DotA2/comments/ai9qin/congratulations_to_th...    474   \n",
       "\n",
       "                                            selftext  stickied subreddit  \\\n",
       "0  Hey /r/DotA2!\\n\\nSince we're at the start of a...      True     DotA2   \n",
       "1  \\nReady the questions! Feel free to ask anythi...      True     DotA2   \n",
       "2                                                        False     DotA2   \n",
       "3                                                        False     DotA2   \n",
       "4  With their win over Evil Geniuses, Virtus Pro ...     False     DotA2   \n",
       "\n",
       "                                               title  \\\n",
       "0                 /r/Dota2 2019 Survey &amp; Updates   \n",
       "1           The 349th Weekly Stupid Questions Thread   \n",
       "2             Shadow in hospital too due to bad food   \n",
       "3                         Lmao, l know why they lose   \n",
       "4  Congratulations to the first team to qualify f...   \n",
       "\n",
       "                                                 url  r_dota2  r_baseball  \n",
       "0  https://www.reddit.com/r/DotA2/comments/ag5vek...        1           0  \n",
       "1  https://www.reddit.com/r/DotA2/comments/aiaulg...        1           0  \n",
       "2                https://i.redd.it/yuvgsf9unrb21.jpg        1           0  \n",
       "3                https://i.redd.it/fneh4ppatqb21.gif        1           0  \n",
       "4  https://www.reddit.com/r/DotA2/comments/ai9qin...        1           0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2['r_dota2'] = 0\n",
    "sub2['r_baseball'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>r_dota2</th>\n",
       "      <th>r_baseball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseballBot</td>\n",
       "      <td>t3_aia3lp</td>\n",
       "      <td>27</td>\n",
       "      <td>/r/baseball/comments/aia3lp/general_discussion...</td>\n",
       "      <td>2</td>\n",
       "      <td>#So what's this thread for?\\n\\n* ~~Discussion ...</td>\n",
       "      <td>True</td>\n",
       "      <td>baseball</td>\n",
       "      <td>[General Discussion] Around the Horn - 1/21/19</td>\n",
       "      <td>https://www.reddit.com/r/baseball/comments/aia...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thedeejus</td>\n",
       "      <td>t3_a6rwz4</td>\n",
       "      <td>125</td>\n",
       "      <td>/r/baseball/comments/a6rwz4/on_the_downvote_br...</td>\n",
       "      <td>310</td>\n",
       "      <td>Hey everybody, we're well aware of the apparen...</td>\n",
       "      <td>True</td>\n",
       "      <td>baseball</td>\n",
       "      <td>On the downvote brigade</td>\n",
       "      <td>https://www.reddit.com/r/baseball/comments/a6r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RealJimBoeheim</td>\n",
       "      <td>t3_ai69pc</td>\n",
       "      <td>222</td>\n",
       "      <td>/r/baseball/comments/ai69pc/harper_confirmed_j...</td>\n",
       "      <td>2288</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>baseball</td>\n",
       "      <td>[Harper] Confirmed: Just called Tony Romo to s...</td>\n",
       "      <td>https://twitter.com/Bharper3407/status/1087200...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wizedex</td>\n",
       "      <td>t3_aiavsr</td>\n",
       "      <td>42</td>\n",
       "      <td>/r/baseball/comments/aiavsr/ja_happ_reds_outbi...</td>\n",
       "      <td>101</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>baseball</td>\n",
       "      <td>J.A. Happ: Reds outbid the Yankees and offered...</td>\n",
       "      <td>https://www.mlbtraderumors.com/2019/01/rosenth...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Too_Hood_95</td>\n",
       "      <td>t3_aiadom</td>\n",
       "      <td>65</td>\n",
       "      <td>/r/baseball/comments/aiadom/verducci_if_mlb_im...</td>\n",
       "      <td>51</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>baseball</td>\n",
       "      <td>[Verducci] If MLB Implements a Significant Rul...</td>\n",
       "      <td>https://www.si.com/mlb/2019/01/17/rob-manfred-...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author       name  num_comments  \\\n",
       "0     BaseballBot  t3_aia3lp            27   \n",
       "1       thedeejus  t3_a6rwz4           125   \n",
       "2  RealJimBoeheim  t3_ai69pc           222   \n",
       "3         Wizedex  t3_aiavsr            42   \n",
       "4     Too_Hood_95  t3_aiadom            65   \n",
       "\n",
       "                                           permalink  score  \\\n",
       "0  /r/baseball/comments/aia3lp/general_discussion...      2   \n",
       "1  /r/baseball/comments/a6rwz4/on_the_downvote_br...    310   \n",
       "2  /r/baseball/comments/ai69pc/harper_confirmed_j...   2288   \n",
       "3  /r/baseball/comments/aiavsr/ja_happ_reds_outbi...    101   \n",
       "4  /r/baseball/comments/aiadom/verducci_if_mlb_im...     51   \n",
       "\n",
       "                                            selftext  stickied subreddit  \\\n",
       "0  #So what's this thread for?\\n\\n* ~~Discussion ...      True  baseball   \n",
       "1  Hey everybody, we're well aware of the apparen...      True  baseball   \n",
       "2                                                        False  baseball   \n",
       "3                                                        False  baseball   \n",
       "4                                                        False  baseball   \n",
       "\n",
       "                                               title  \\\n",
       "0     [General Discussion] Around the Horn - 1/21/19   \n",
       "1                            On the downvote brigade   \n",
       "2  [Harper] Confirmed: Just called Tony Romo to s...   \n",
       "3  J.A. Happ: Reds outbid the Yankees and offered...   \n",
       "4  [Verducci] If MLB Implements a Significant Rul...   \n",
       "\n",
       "                                                 url  r_dota2  r_baseball  \n",
       "0  https://www.reddit.com/r/baseball/comments/aia...        0           1  \n",
       "1  https://www.reddit.com/r/baseball/comments/a6r...        0           1  \n",
       "2  https://twitter.com/Bharper3407/status/1087200...        0           1  \n",
       "3  https://www.mlbtraderumors.com/2019/01/rosenth...        0           1  \n",
       "4  https://www.si.com/mlb/2019/01/17/rob-manfred-...        0           1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([sub1, sub2], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>r_dota2</th>\n",
       "      <th>r_baseball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VRCkid</td>\n",
       "      <td>t3_ag5vek</td>\n",
       "      <td>171</td>\n",
       "      <td>/r/DotA2/comments/ag5vek/rdota2_2019_survey_up...</td>\n",
       "      <td>274</td>\n",
       "      <td>Hey /r/DotA2!\\n\\nSince we're at the start of a...</td>\n",
       "      <td>True</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>/r/Dota2 2019 Survey &amp;amp; Updates</td>\n",
       "      <td>https://www.reddit.com/r/DotA2/comments/ag5vek...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VRCbot</td>\n",
       "      <td>t3_aiaulg</td>\n",
       "      <td>64</td>\n",
       "      <td>/r/DotA2/comments/aiaulg/the_349th_weekly_stup...</td>\n",
       "      <td>10</td>\n",
       "      <td>\\nReady the questions! Feel free to ask anythi...</td>\n",
       "      <td>True</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>The 349th Weekly Stupid Questions Thread</td>\n",
       "      <td>https://www.reddit.com/r/DotA2/comments/aiaulg...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwer4790</td>\n",
       "      <td>t3_ai9hp2</td>\n",
       "      <td>321</td>\n",
       "      <td>/r/DotA2/comments/ai9hp2/shadow_in_hospital_to...</td>\n",
       "      <td>1241</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>Shadow in hospital too due to bad food</td>\n",
       "      <td>https://i.redd.it/yuvgsf9unrb21.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PSGLGD-Baka</td>\n",
       "      <td>t3_ai8f9v</td>\n",
       "      <td>169</td>\n",
       "      <td>/r/DotA2/comments/ai8f9v/lmao_l_know_why_they_...</td>\n",
       "      <td>1257</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>Lmao, l know why they lose</td>\n",
       "      <td>https://i.redd.it/fneh4ppatqb21.gif</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lelANDtoplel</td>\n",
       "      <td>t3_ai9qin</td>\n",
       "      <td>99</td>\n",
       "      <td>/r/DotA2/comments/ai9qin/congratulations_to_th...</td>\n",
       "      <td>474</td>\n",
       "      <td>With their win over Evil Geniuses, Virtus Pro ...</td>\n",
       "      <td>False</td>\n",
       "      <td>DotA2</td>\n",
       "      <td>Congratulations to the first team to qualify f...</td>\n",
       "      <td>https://www.reddit.com/r/DotA2/comments/ai9qin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author       name  num_comments  \\\n",
       "0        VRCkid  t3_ag5vek           171   \n",
       "1        VRCbot  t3_aiaulg            64   \n",
       "2      qwer4790  t3_ai9hp2           321   \n",
       "3   PSGLGD-Baka  t3_ai8f9v           169   \n",
       "4  lelANDtoplel  t3_ai9qin            99   \n",
       "\n",
       "                                           permalink  score  \\\n",
       "0  /r/DotA2/comments/ag5vek/rdota2_2019_survey_up...    274   \n",
       "1  /r/DotA2/comments/aiaulg/the_349th_weekly_stup...     10   \n",
       "2  /r/DotA2/comments/ai9hp2/shadow_in_hospital_to...   1241   \n",
       "3  /r/DotA2/comments/ai8f9v/lmao_l_know_why_they_...   1257   \n",
       "4  /r/DotA2/comments/ai9qin/congratulations_to_th...    474   \n",
       "\n",
       "                                            selftext  stickied subreddit  \\\n",
       "0  Hey /r/DotA2!\\n\\nSince we're at the start of a...      True     DotA2   \n",
       "1  \\nReady the questions! Feel free to ask anythi...      True     DotA2   \n",
       "2                                                        False     DotA2   \n",
       "3                                                        False     DotA2   \n",
       "4  With their win over Evil Geniuses, Virtus Pro ...     False     DotA2   \n",
       "\n",
       "                                               title  \\\n",
       "0                 /r/Dota2 2019 Survey &amp; Updates   \n",
       "1           The 349th Weekly Stupid Questions Thread   \n",
       "2             Shadow in hospital too due to bad food   \n",
       "3                         Lmao, l know why they lose   \n",
       "4  Congratulations to the first team to qualify f...   \n",
       "\n",
       "                                                 url  r_dota2  r_baseball  \n",
       "0  https://www.reddit.com/r/DotA2/comments/ag5vek...        1           0  \n",
       "1  https://www.reddit.com/r/DotA2/comments/aiaulg...        1           0  \n",
       "2                https://i.redd.it/yuvgsf9unrb21.jpg        1           0  \n",
       "3                https://i.redd.it/fneh4ppatqb21.gif        1           0  \n",
       "4  https://www.reddit.com/r/DotA2/comments/ai9qin...        1           0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `res.json()` to convert the response into a dictionary format and set this to a variable. \n",
    "\n",
    "```python\n",
    "data = res.json()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['r_dota2']\n",
    "X1 = data['title']\n",
    "X2 = data['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: r_dota2, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   /r/Dota2 2019 Survey &amp; Updates\n",
       "1             The 349th Weekly Stupid Questions Thread\n",
       "2               Shadow in hospital too due to bad food\n",
       "3                           Lmao, l know why they lose\n",
       "4    Congratulations to the first team to qualify f...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "## NLP\n",
    "\n",
    "#### Use `CountVectorizer` or `TfidfVectorizer` from scikit-learn to create features from the thread titles and descriptions (NOTE: Not all threads have a description)\n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, target, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415                         Turning Point for Team Liquid\n",
       "273                            Lmao, l know why they lose\n",
       "1782       [General Discussion] Around the Horn - 1/21/19\n",
       "250     The major host shaved his beard off after the ...\n",
       "413                                The Chinese Masterplan\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_words(title):\n",
    "    title_text = BeautifulSoup(title).get_text()\n",
    "    lower_case = title_text.lower()\n",
    "    retokenizer = RegexpTokenizer(r'[a-z]+')\n",
    "    words = retokenizer.tokenize(lower_case)\n",
    "    stops = set(stopwords.words('english'))\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 50 of 1512\n",
      "\n",
      "Title 100 of 1512\n",
      "\n",
      "Title 150 of 1512\n",
      "\n",
      "Title 200 of 1512\n",
      "\n",
      "Title 250 of 1512\n",
      "\n",
      "Title 300 of 1512\n",
      "\n",
      "Title 350 of 1512\n",
      "\n",
      "Title 400 of 1512\n",
      "\n",
      "Title 450 of 1512\n",
      "\n",
      "Title 500 of 1512\n",
      "\n",
      "Title 550 of 1512\n",
      "\n",
      "Title 600 of 1512\n",
      "\n",
      "Title 650 of 1512\n",
      "\n",
      "Title 700 of 1512\n",
      "\n",
      "Title 750 of 1512\n",
      "\n",
      "Title 800 of 1512\n",
      "\n",
      "Title 850 of 1512\n",
      "\n",
      "Title 900 of 1512\n",
      "\n",
      "Title 950 of 1512\n",
      "\n",
      "Title 1000 of 1512\n",
      "\n",
      "Title 1050 of 1512\n",
      "\n",
      "Title 1100 of 1512\n",
      "\n",
      "Title 1150 of 1512\n",
      "\n",
      "Title 1200 of 1512\n",
      "\n",
      "Title 1250 of 1512\n",
      "\n",
      "Title 1300 of 1512\n",
      "\n",
      "Title 1350 of 1512\n",
      "\n",
      "Title 1400 of 1512\n",
      "\n",
      "Title 1450 of 1512\n",
      "\n",
      "Title 1500 of 1512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_titles = X_train.size\n",
    "cleaned_train_titles = []\n",
    "\n",
    "for i in range(0, num_titles):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if((i+1) % 50 == 0):\n",
    "        print(\"Title %d of %d\\n\" % ( i+1, num_titles ))                                                                    \n",
    "    cleaned_train_titles.append( title_to_words( X_train.iloc[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 50 of 648\n",
      "\n",
      "Title 100 of 648\n",
      "\n",
      "Title 150 of 648\n",
      "\n",
      "Title 200 of 648\n",
      "\n",
      "Title 250 of 648\n",
      "\n",
      "Title 300 of 648\n",
      "\n",
      "Title 350 of 648\n",
      "\n",
      "Title 400 of 648\n",
      "\n",
      "Title 450 of 648\n",
      "\n",
      "Title 500 of 648\n",
      "\n",
      "Title 550 of 648\n",
      "\n",
      "Title 600 of 648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_titles2 = X_test.size\n",
    "cleaned_test_titles = []\n",
    "\n",
    "for i in range(0, num_titles2):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if((i+1) % 50 == 0):\n",
    "        print(\"Title %d of %d\\n\" % ( i+1, num_titles2 ))                                                                    \n",
    "    cleaned_test_titles.append( title_to_words( X_test.iloc[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['general discussion around horn',\n",
       " 'director looks cool match',\n",
       " 'rosenthal one possible delay announcement reds trade yankees sonny gray jonheyman said yesterday finalized reds might trying sign gray extension part deal confirmed discussion would make sense',\n",
       " 'starting shortstops guess year',\n",
       " 'maffia works']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turning point team liquid',\n",
       " 'lmao l know lose',\n",
       " 'general discussion around horn',\n",
       " 'major host shaved beard first ehome vs fnatic game',\n",
       " 'chinese masterplan']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=41)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=200)\n",
    "\n",
    "train_features = vectorizer.fit(cleaned_train_titles)\n",
    "\n",
    "train_features = vectorizer.transform(cleaned_train_titles)\n",
    "test_features = vectorizer.transform(cleaned_test_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict(list(zip(vectorizer.get_feature_names(),log_reg.coef_[0])))\n",
    "feature_df = pd.DataFrame(features, index=['coef']).T\n",
    "feature_df['abs_coef'] = abs(feature_df['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qualify</th>\n",
       "      <td>1.317536</td>\n",
       "      <td>1.317536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>-1.269444</td>\n",
       "      <td>1.269444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>give</th>\n",
       "      <td>-1.099655</td>\n",
       "      <td>1.099655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>-0.898013</td>\n",
       "      <td>0.898013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lot</th>\n",
       "      <td>0.814378</td>\n",
       "      <td>0.814378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>already</th>\n",
       "      <td>-0.798472</td>\n",
       "      <td>0.798472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>-0.786887</td>\n",
       "      <td>0.786887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molitor</th>\n",
       "      <td>-0.772896</td>\n",
       "      <td>0.772896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seasons</th>\n",
       "      <td>-0.772896</td>\n",
       "      <td>0.772896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>-0.715570</td>\n",
       "      <td>0.715570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki</th>\n",
       "      <td>0.707308</td>\n",
       "      <td>0.707308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dota</th>\n",
       "      <td>0.694870</td>\n",
       "      <td>0.694870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>-0.681881</td>\n",
       "      <td>0.681881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>0.628709</td>\n",
       "      <td>0.628709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fact</th>\n",
       "      <td>-0.623693</td>\n",
       "      <td>0.623693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.539196</td>\n",
       "      <td>0.539196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.516860</td>\n",
       "      <td>0.516860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>0.501032</td>\n",
       "      <td>0.501032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>around</th>\n",
       "      <td>0.451244</td>\n",
       "      <td>0.451244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>especially</th>\n",
       "      <td>0.451244</td>\n",
       "      <td>0.451244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef  abs_coef\n",
       "qualify     1.317536  1.317536\n",
       "year       -1.269444  1.269444\n",
       "give       -1.099655  1.099655\n",
       "see        -0.898013  0.898013\n",
       "lot         0.814378  0.814378\n",
       "already    -0.798472  0.798472\n",
       "end        -0.786887  0.786887\n",
       "molitor    -0.772896  0.772896\n",
       "seasons    -0.772896  0.772896\n",
       "right      -0.715570  0.715570\n",
       "wiki        0.707308  0.707308\n",
       "dota        0.694870  0.694870\n",
       "time       -0.681881  0.681881\n",
       "team        0.628709  0.628709\n",
       "fact       -0.623693  0.623693\n",
       "would       0.539196  0.539196\n",
       "new         0.516860  0.516860\n",
       "really      0.501032  0.501032\n",
       "around      0.451244  0.451244\n",
       "especially  0.451244  0.451244"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.sort_values('abs_coef', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admins', 'already', 'also', 'another', 'anything']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1512x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7681 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<648x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2603 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting subreddit using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9351851851851852"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9074074074074074"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - class `0` for one of your subreddits and `1` for the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "source": [
    "The model shows very high scores based on the title text, a score of 0.9905!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a `RandomForestClassifier` model to predict which subreddit a given post belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9351851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9074074074074074"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = RandomForestClassifier()\n",
    "\n",
    "dt.fit(train_features, y_train)\n",
    "print(dt.score(train_features, y_train))\n",
    "dt.score(test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. \n",
    "- **Bonus**: Use `GridSearchCV` with `Pipeline` to optimize your `CountVectorizer`/`TfidfVectorizer` and classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score:\t0.935 ± 0.013\n"
     ]
    }
   ],
   "source": [
    "s = cross_val_score(dt, train_features, y_train, cv=cv, n_jobs=-1)\n",
    "print(\"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Random Forest\", s.mean().round(3), s.std().round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process using a different classifier (e.g. `MultinomialNB`, `LogisticRegression`, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9074074074074074\n",
      "Decision Tree Score:\t0.935 ± 0.013\n"
     ]
    }
   ],
   "source": [
    "dt2 = DecisionTreeClassifier()\n",
    "\n",
    "dt2.fit(train_features, y_train)\n",
    "\n",
    "print(dt.score(test_features, y_test))\n",
    "\n",
    "s2 = cross_val_score(dt2, train_features, y_train, cv=cv, n_jobs=-1)\n",
    "print(\"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Decision Tree\", s2.mean().round(3), s2.std().round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Score:\t0.935 ± 0.013\n"
     ]
    }
   ],
   "source": [
    "dt3 = BaggingClassifier()\n",
    "\n",
    "dt3.fit(train_features, y_train)\n",
    "\n",
    "s3 = cross_val_score(dt3, train_features, y_train, cv=cv, n_jobs=-1)\n",
    "print(\"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Bagging\", s3.mean().round(3), s3.std().round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'll repeat the procedure using the post text instead of the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, target, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 50 of 1512\n",
      "\n",
      "Title 100 of 1512\n",
      "\n",
      "Title 150 of 1512\n",
      "\n",
      "Title 200 of 1512\n",
      "\n",
      "Title 250 of 1512\n",
      "\n",
      "Title 300 of 1512\n",
      "\n",
      "Title 350 of 1512\n",
      "\n",
      "Title 400 of 1512\n",
      "\n",
      "Title 450 of 1512\n",
      "\n",
      "Title 500 of 1512\n",
      "\n",
      "Title 550 of 1512\n",
      "\n",
      "Title 600 of 1512\n",
      "\n",
      "Title 650 of 1512\n",
      "\n",
      "Title 700 of 1512\n",
      "\n",
      "Title 750 of 1512\n",
      "\n",
      "Title 800 of 1512\n",
      "\n",
      "Title 850 of 1512\n",
      "\n",
      "Title 900 of 1512\n",
      "\n",
      "Title 950 of 1512\n",
      "\n",
      "Title 1000 of 1512\n",
      "\n",
      "Title 1050 of 1512\n",
      "\n",
      "Title 1100 of 1512\n",
      "\n",
      "Title 1150 of 1512\n",
      "\n",
      "Title 1200 of 1512\n",
      "\n",
      "Title 1250 of 1512\n",
      "\n",
      "Title 1300 of 1512\n",
      "\n",
      "Title 1350 of 1512\n",
      "\n",
      "Title 1400 of 1512\n",
      "\n",
      "Title 1450 of 1512\n",
      "\n",
      "Title 1500 of 1512\n",
      "\n",
      "Title 50 of 648\n",
      "\n",
      "Title 100 of 648\n",
      "\n",
      "Title 150 of 648\n",
      "\n",
      "Title 200 of 648\n",
      "\n",
      "Title 250 of 648\n",
      "\n",
      "Title 300 of 648\n",
      "\n",
      "Title 350 of 648\n",
      "\n",
      "Title 400 of 648\n",
      "\n",
      "Title 450 of 648\n",
      "\n",
      "Title 500 of 648\n",
      "\n",
      "Title 550 of 648\n",
      "\n",
      "Title 600 of 648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_text = X2_train.size\n",
    "cleaned_train_text = []\n",
    "\n",
    "for i in range(0, num_text):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if((i+1) % 50 == 0):\n",
    "        print(\"Title %d of %d\\n\" % ( i+1, num_text ))                                                                    \n",
    "    cleaned_train_text.append( title_to_words( X2_train.iloc[i] ))\n",
    "    \n",
    "num_text2 = X2_test.size\n",
    "cleaned_test_text = []\n",
    "\n",
    "for i in range(0, num_text2):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if((i+1) % 50 == 0):\n",
    "        print(\"Title %d of %d\\n\" % ( i+1, num_text2 ))                                                                    \n",
    "    cleaned_test_text.append( title_to_words( X2_test.iloc[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'thread discussion yesterday games excitement today games staring window waiting spring general questions mildly interesting facts praising santa anything else worth sharing asking warrant post game threads use games schedule sidebar navigate team want game thread featured posts links join official r baseball discord server https www reddit com r baseball comments bxp official rbaseball discord server new r baseball baseball check https www reddit com r baseball comments ofctq new comers guide common baseball terms newcomers guide common baseball terms u aagpeng reviewed r baseball offseason schedule hot stove guide https www reddit com r baseball comments taccj rbaseball offseason schedule hot stove guide book club january book rule work ben lindbergh sam miller discussion held january https www reddit com r baseball comments ac vmu reminder january book month note best user experience recommend disabling reddit redesign using r baseball week schedule day feature sunday baseball monday seriously baseball tuesday hall fame announcement wednesday come back baseball thursday ideas friday spring yet saturday r baseball book club discussion rule work',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=200)\n",
    "\n",
    "train_features2 = vectorizer.fit(cleaned_train_text)\n",
    "\n",
    "train_features2 = vectorizer.transform(cleaned_train_text)\n",
    "test_features2 = vectorizer.transform(cleaned_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1512x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<648x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3995 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train_features2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.score(train_features2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416666666666666"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(test_features2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6234567901234568"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = RandomForestClassifier()\n",
    "dt.fit(train_features2, y_train)\n",
    "dt.score(test_features2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score:\t0.632 ± 0.017\n"
     ]
    }
   ],
   "source": [
    "s = cross_val_score(dt, train_features2, y_train, cv=cv, n_jobs=-1)\n",
    "print(\"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Random Forest\", s.mean().round(3), s.std().round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "---\n",
    "Put your executive summary in a Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was quite easy for the Random Forest model to predict the subreddit based on the chosen 200 words.  Scores of over 0.99 are pretty damn impressive!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
